{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aaf1cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b1a31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b915588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('df2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e9a7e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 232 entries, 10 to 539\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Year                  232 non-null    int64  \n",
      " 1   Product_type          232 non-null    object \n",
      " 2   Ticker                232 non-null    object \n",
      " 3   market_cap_cur        232 non-null    float64\n",
      " 4   shares_out            232 non-null    float64\n",
      " 5   year_inc              232 non-null    float64\n",
      " 6   Previous_SBs          232 non-null    int64  \n",
      " 7   Yearly_Ad_Count       232 non-null    int64  \n",
      " 8   New                   232 non-null    int64  \n",
      " 9   overperform           232 non-null    int64  \n",
      " 10  Ave_inflation_rate    232 non-null    float64\n",
      " 11  CPI                   232 non-null    float64\n",
      " 12  USD_per_euro          232 non-null    float64\n",
      " 13  Annual_change_GDP     232 non-null    float64\n",
      " 14  VIX                   232 non-null    float64\n",
      " 15  change_in_businesses  232 non-null    float64\n",
      "dtypes: float64(9), int64(5), object(2)\n",
      "memory usage: 30.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(axis='columns' , columns=['close', 'close_plus6', 'spx_close', 'spx_plus6', 'return', 'SP_return' ], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2902b64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_type  New\n",
       "Alcohol       0      0.538462\n",
       "Car           0      0.282051\n",
       "Clothing      0      0.333333\n",
       "Film          0      0.416667\n",
       "Food          0      0.560000\n",
       "              1      0.625000\n",
       "Gaming        0      1.000000\n",
       "Goods         0      0.437500\n",
       "              1      0.000000\n",
       "Service       0      0.555556\n",
       "              1      0.600000\n",
       "Soft drink    0      0.600000\n",
       "              1      1.000000\n",
       "TV            0      0.714286\n",
       "Technology    0      0.400000\n",
       "              1      0.000000\n",
       "Website       0      0.363636\n",
       "              1      0.000000\n",
       "Wireless      0      0.333333\n",
       "Name: overperform, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Product_type','New'])['overperform'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3eaae772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6474aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df.drop('overperform',axis=1)\n",
    "y = df['overperform']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=714)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad962638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick transformers\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[('encoder', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ec5d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split columns into numeric and categorical\n",
    "numeric_features = ['Year', 'market_cap_cur', 'shares_out', 'year_inc', 'Previous_SBs', 'Yearly_Ad_Count','New', 'Ave_inflation_rate', 'CPI','USD_per_euro', 'Annual_change_GDP','VIX','change_in_businesses']\n",
    "categorical_features = ['Product_type', 'Ticker']\n",
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "   ,('categorical', categorical_transformer, categorical_features)\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d10e1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9814d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_params = [0.001,0.01,0.1,1,10,100,1000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1cce18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0]\n",
      " [20  0]]\n",
      "[[24  3]\n",
      " [17  3]]\n",
      "[[22  5]\n",
      " [16  4]]\n",
      "[[22  5]\n",
      " [13  7]]\n",
      "[[22  5]\n",
      " [14  6]]\n",
      "[[22  5]\n",
      " [15  5]]\n",
      "[[23  4]\n",
      " [15  5]]\n",
      "[[23  4]\n",
      " [15  5]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.507407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.596296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.605556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.574074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000000.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             C Recall Precision   ROC-AOC\n",
       "0        0.001    0.0       0.0  0.514815\n",
       "1        0.010   0.15       0.5  0.507407\n",
       "2        0.100    0.2  0.444444  0.555556\n",
       "3        1.000   0.35  0.583333  0.583333\n",
       "4       10.000    0.3  0.545455  0.596296\n",
       "5      100.000   0.25       0.5  0.605556\n",
       "6     1000.000   0.25  0.555556  0.574074\n",
       "7  1000000.000   0.25  0.555556  0.588889"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through C_params\n",
    "j = 0\n",
    "\n",
    "table = pd.DataFrame(columns = ['C','Recall','Precision','ROC-AOC'])\n",
    "table['C'] = C_params\n",
    "for C in C_params:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor',LogisticRegression(C=C,random_state=42))\n",
    "           ])\n",
    "    lr_model = pipeline.fit(X_train, y_train) \n",
    "    predictions = lr_model.predict(X_test)\n",
    "    probs = pipeline.predict_proba(X_test)[:, 1]\n",
    "    # Predict using model\n",
    "    #print('C is ',C)\n",
    "    #print ('Recall: ',metrics.recall_score(y_test, predictions) )\n",
    "    #print ('Precision: ',metrics.precision_score(y_test, predictions) )\n",
    "    print (confusion_matrix(y_test, predictions))\n",
    "    #print ('AOC: ',metrics.roc_auc_score(y, probs))\n",
    "    table.iloc[j,1] = metrics.recall_score(y_test, predictions)\n",
    "    table.iloc[j,2] = metrics.precision_score(y_test, predictions)\n",
    "    table.iloc[j,3] = metrics.roc_auc_score(y_test, probs)\n",
    "    j+=1\n",
    "table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd29c899",
   "metadata": {},
   "source": [
    "Looks like decreasing penalties improves the model. If this ends up near the top this should come out in GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0cdbd252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34285714 0.65714286 0.51428571 0.53333333]\n",
      "Mean cross validation test score: 0.5119047619047619\n",
      "Mean cross validation train score: 0.6091575091575092\n",
      "Standard deviation in cv test scores: 0.11195540900484524\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lr_model,X_test,y_test,cv=4,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lr_model,X_train,y_train,cv=4,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_lr_test= cv_scores_test.mean()\n",
    "cv_scores_lr_train= cv_scores_train.mean()\n",
    "cv_scores_std_lr= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lr_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lr_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcec7c9",
   "metadata": {},
   "source": [
    "Not really looking that good with the large difference between training and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c184541",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65278a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  5]\n",
      " [12  8]]\n"
     ]
    }
   ],
   "source": [
    "# Reset the pipeline and try KNN\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor', KNeighborsClassifier(p=2,weights='distance',n_neighbors=6))\n",
    "           ])\n",
    "\n",
    "knn = pipeline.fit(X_train,y_train)\n",
    "\n",
    "# Predict using model:\n",
    "\n",
    "y_predict_knn = pipeline.predict(X_test)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_knn)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ed7a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77142857 0.62857143 0.45714286 0.83333333]\n",
      "Mean cross validation test score: 0.6726190476190476\n",
      "Mean cross validation train score: 0.5104510073260073\n",
      "Standard deviation in cv scores: 0.14488149039302228\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(pipeline,X_test,y_test,cv=4,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(pipeline,X_train,y_train,cv=4,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_knn_test= cv_scores_test.mean()\n",
    "cv_scores_knn_train= cv_scores_train.mean()\n",
    "cv_scores_std_knn= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_knn_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_knn_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14139bba",
   "metadata": {},
   "source": [
    "### Something seems strange here with an outlier model\n",
    "\n",
    "Good choice to gridsearch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1bb63",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9a00210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  5]\n",
      " [14  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor', SVC(kernel='linear'))\n",
    "           ])\n",
    "svm = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using model:\n",
    "\n",
    "y_predict_svm = pipeline.predict(X_test)\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_svm)\n",
    "print(cnf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7084bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.41666667 0.55       0.6        0.8       ]\n",
      "Mean cross validation test score: 0.6233333333333334\n",
      "Mean cross validation train score: 0.5753991596638655\n",
      "Standard deviation in cv scores: 0.1384838538522733\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(pipeline,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(pipeline,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_svm_test= cv_scores_test.mean()\n",
    "cv_scores_svm_train= cv_scores_train.mean()\n",
    "cv_scores_std_svm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_svm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_svm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e6775",
   "metadata": {},
   "source": [
    "Again there seem to be cuts that perform badly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1f4bc",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27a01cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  3]\n",
      " [18  2]]\n",
      "0.5531914893617021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor', RandomForestClassifier(bootstrap=True,n_estimators=40,criterion='entropy', max_depth=4))\n",
    "           ])\n",
    "rf = pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_rf = rf.predict(X_test)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_rf)\n",
    "print(cnf_matrix)\n",
    "Accuracy_rf=rf.score(X_test,y_test)\n",
    "print(Accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c5409ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.85097641e-02, 2.73376464e-02, 6.09375813e-02, 5.26322237e-02,\n",
       "       6.09329372e-02, 2.17861245e-02, 4.73590252e-03, 4.28723034e-02,\n",
       "       2.87664590e-02, 3.85025830e-02, 4.96523840e-02, 4.58802446e-02,\n",
       "       7.47038437e-02, 6.17166048e-03, 2.29966915e-02, 0.00000000e+00,\n",
       "       1.25270855e-02, 1.50488805e-02, 0.00000000e+00, 1.80444004e-03,\n",
       "       1.74513136e-02, 1.72840155e-02, 7.45580979e-03, 1.79881786e-02,\n",
       "       1.80695228e-02, 1.47898935e-02, 2.06023112e-03, 0.00000000e+00,\n",
       "       2.05655351e-02, 0.00000000e+00, 2.98045502e-03, 0.00000000e+00,\n",
       "       1.98971472e-02, 5.99168705e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.01133587e-02, 1.85322751e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       6.34018094e-04, 1.23192819e-02, 1.70303801e-03, 3.62160402e-03,\n",
       "       5.91061066e-03, 1.45479689e-03, 6.50197915e-03, 1.56997831e-02,\n",
       "       1.26324860e-02, 0.00000000e+00, 1.15213451e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.06111446e-03,\n",
       "       0.00000000e+00, 5.38495770e-03, 0.00000000e+00, 8.22137476e-03,\n",
       "       4.49184859e-03, 0.00000000e+00, 0.00000000e+00, 1.09826458e-02,\n",
       "       2.73934396e-03, 2.06904450e-03, 6.08836461e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.20364256e-03,\n",
       "       2.12234146e-03, 1.52473140e-03, 0.00000000e+00, 5.16693257e-03,\n",
       "       1.67349317e-02, 0.00000000e+00, 0.00000000e+00, 1.03208392e-03,\n",
       "       2.77771292e-03, 8.00722271e-05, 1.66121182e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.05823809e-02, 4.28973769e-02,\n",
       "       1.46783411e-03, 0.00000000e+00, 0.00000000e+00, 2.50615866e-03,\n",
       "       2.45380554e-03, 1.06502280e-02, 2.33784649e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.51303432e-03])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf['regressor'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1613c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6        0.51428571 0.54285714 0.73333333]\n",
      "Mean cross validation test score: 0.5976190476190477\n",
      "Mean cross validation train score: 0.5707188644688646\n",
      "Standard deviation in cv scores: 0.0842130437325114\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(rf,X_test,y_test,cv=4,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(rf,X_train,y_train,cv=4,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "cv_scores_std_rf= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_rf_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_rf_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa6747",
   "metadata": {},
   "source": [
    "RF seems far more consistent but performs generally worse. Average with it maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eed780",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6747e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  5]\n",
      " [12  8]]\n",
      "0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor',  GradientBoostingClassifier(subsample=0.8, learning_rate=0.01 , n_estimators=100, random_state=5, max_depth=4, max_leaf_nodes=30))\n",
    "           ])\n",
    "gbc = pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_gbc)\n",
    "print(cnf_matrix)\n",
    "Accuracy_gbc=gbc.score(X_test,y_test)\n",
    "print(Accuracy_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7506b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4        0.6        0.65714286 0.63333333]\n",
      "Mean cross validation test score: 0.5726190476190476\n",
      "Mean cross validation train score: 0.582257326007326\n",
      "Standard deviation in cv scores: 0.1017073633278439\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(gbc,X_test,y_test,cv=4,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(gbc,X_train,y_train,cv=4,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_gbc_test= cv_scores_test.mean()\n",
    "cv_scores_gbc_train= cv_scores_train.mean()\n",
    "cv_scores_std_gbc= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_gbc_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_gbc_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78031528",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "983ae769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>ROC-AUC train score</th>\n",
       "      <th>ROC-AUC test score</th>\n",
       "      <th>ROC-AUC test std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.609158</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.111955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.510451</td>\n",
       "      <td>0.672619</td>\n",
       "      <td>0.144881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.575399</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.138484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.570719</td>\n",
       "      <td>0.597619</td>\n",
       "      <td>0.084213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.582257</td>\n",
       "      <td>0.572619</td>\n",
       "      <td>0.101707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  ROC-AUC train score  ROC-AUC test score  \\\n",
       "0  Logistic Regression             0.609158            0.511905   \n",
       "1                  KNN             0.510451            0.672619   \n",
       "2                  SVM             0.575399            0.623333   \n",
       "3        Random Forest             0.570719            0.597619   \n",
       "4       Gradient Boost             0.582257            0.572619   \n",
       "\n",
       "   ROC-AUC test std  \n",
       "0          0.111955  \n",
       "1          0.144881  \n",
       "2          0.138484  \n",
       "3          0.084213  \n",
       "4          0.101707  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLabels = [ 'Logistic Regression','KNN','SVM','Random Forest','Gradient Boost']\n",
    "score_test= [  cv_scores_lr_test,cv_scores_knn_test,cv_scores_svm_test,cv_scores_rf_test,cv_scores_gbc_test]\n",
    "score_train= [  cv_scores_lr_train,cv_scores_knn_train,cv_scores_svm_train,cv_scores_rf_train,cv_scores_gbc_train]\n",
    "std_test= [  cv_scores_std_lr,cv_scores_std_knn,cv_scores_std_svm,cv_scores_std_rf,cv_scores_std_gbc]\n",
    "\n",
    "#score_tab_acc = pd.DataFrame(list(zip(myLabels, Accuracy_score)), \n",
    "               #columns =['Algorithm', 'Model accuracy score']) \n",
    "\n",
    "score_tab = pd.DataFrame(list(zip(myLabels, score_train, score_test, std_test)), \n",
    "               columns =['Algorithm', 'ROC-AUC train score', 'ROC-AUC test score',  'ROC-AUC test std']) \n",
    "#print(score_tab_acc)\n",
    "\n",
    "score_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec3abed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\snakes\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\snakes\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\snakes\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='roc_auc', cv=4, n_jobs=-1)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#gs = gs.fit(X_train, y_train)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(rf, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, param_grid\u001b[38;5;241m=\u001b[39mparam_grid ,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, y_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m grid\u001b[38;5;241m.\u001b[39mscore(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], y_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid\u001b[38;5;241m.\u001b[39mbest_estimator_) \n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\snakes\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\snakes\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto',random_state=1, n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10,12,16], \"n_estimators\": [50, 100,400,700,1000]}\n",
    "\n",
    "#gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "#gs = gs.fit(X_train, y_train)\n",
    "\n",
    "grid = GridSearchCV(rf, cv=4, n_jobs=-1, param_grid=param_grid ,scoring='roc_auc')\n",
    "grid.fit(X_train['text'], y_train['output'])\n",
    "grid.score(X_test['text'], y_test['output'])\n",
    "print(grid.best_estimator_) \n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd91e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snakes]",
   "language": "python",
   "name": "conda-env-snakes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
